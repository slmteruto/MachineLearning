{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 개요\n",
    "\n",
    "    - 파이썬으로 구현된 쉽고 간결한 딥러닝 라이브러리\n",
    "    - 구글의 엔지니어가 만듬 (2015/03)\n",
    "    - 내부적으로는 텐서프로우 엔진이 구동되지만 직관적인 API로 쉽게 딥러닝 실험을 할 수 있도록 지원\n",
    "    \n",
    "    \n",
    "    책 추천 - 케라스 창시자에게 배우는 딥러닝 \n",
    "    \n",
    "    \n",
    "# 2. 주요 특징\n",
    "\n",
    "    - 모듈화\n",
    "    - 최소주의\n",
    "    - 쉬운 확장성\n",
    "    - 파이썬 기반"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 설치\n",
    "\n",
    "    pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "import mglearn\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()    \n",
    "# 한글폰트가 기본적으로 없다.  그래서 따로 등록해서 사용하면 됨\n",
    "font_name\n",
    "#(c\\windows\\fonts  가 기본폰트)\n",
    "\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "# - 마이너스 표시도 깨진다.\n",
    "mpl.rcParams[\"axes.unicode_minus\"]=False    #마이너스를 문자로 쓰지 않고 숫자로 쓰겠다. 라는 뜻\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential  # 모델 생성용\n",
    "from keras.models import load_model  # 저장한 모델 불러오기\n",
    "from keras.layers.core import Dense  # shape 조정\n",
    "from keras.optimizers import RMSprop #\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using TensorFlow backend. \n",
    "        = backend로는 텐서플로우를 이용한다는 것.\n",
    "        \n",
    "    \n",
    "    사용자 -> keras 설치됐으면 keras 폴더가 생성된다. -> 안에 json파일은 설정파일\n",
    "    \n",
    "    \n",
    "    {\n",
    "    \"floatx\": \"float32\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"backend\": \"tensorflow\",\n",
    "    \"image_data_format\": \"channels_last\"\n",
    "    }\n",
    "    \n",
    "    여기서 보면 backend의 기본값이 뭘로 되있는지 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습1. 혈핵형 예측 \n",
    "\n",
    "    x09.txt  데이터 이용\n",
    "    32번째 부터 실제 데이터이고 그 전까지는 설명\n",
    "\n",
    "    선형회귀를 위한 데이터 \n",
    "    \n",
    "    - 07. 텐서플로우-선형, 로지스틱 참고\n",
    "    \n",
    "        tf의 placeholder를 사용했다.\n",
    "        \n",
    "        그래프를 생성하고 run으로 실행 시켰다는 것을 기억해라\n",
    "        \n",
    "        그런데 이렇게 간단한것도 tf로 하면 되게 불편하지 않나? 라는 생각\n",
    "        \n",
    "        데이터가 복잡하다면 유리하겠지만 간단한 것을 구현하기엔 어렵다. \n",
    "        \n",
    "        그래서 케라스가 등장 \n",
    "        \n",
    "    - tf 이전 엔진\n",
    "        theano\n",
    "        \n",
    "            keras에서는 tensorflow와 theano 둘 다 실행 가능 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형 회귀 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,  84.,  46., 354.],\n",
       "       [  2.,   1.,  73.,  20., 190.],\n",
       "       [  3.,   1.,  65.,  52., 405.],\n",
       "       [  4.,   1.,  70.,  30., 263.],\n",
       "       [  5.,   1.,  76.,  57., 451.],\n",
       "       [  6.,   1.,  69.,  25., 302.],\n",
       "       [  7.,   1.,  63.,  28., 288.],\n",
       "       [  8.,   1.,  72.,  36., 385.],\n",
       "       [  9.,   1.,  79.,  57., 402.],\n",
       "       [ 10.,   1.,  75.,  44., 365.],\n",
       "       [ 11.,   1.,  27.,  24., 209.],\n",
       "       [ 12.,   1.,  89.,  31., 290.],\n",
       "       [ 13.,   1.,  65.,  52., 346.],\n",
       "       [ 14.,   1.,  57.,  23., 254.],\n",
       "       [ 15.,   1.,  59.,  60., 395.],\n",
       "       [ 16.,   1.,  69.,  48., 434.],\n",
       "       [ 17.,   1.,  60.,  34., 220.],\n",
       "       [ 18.,   1.,  79.,  51., 374.],\n",
       "       [ 19.,   1.,  75.,  50., 308.],\n",
       "       [ 20.,   1.,  82.,  34., 220.],\n",
       "       [ 21.,   1.,  59.,  46., 311.],\n",
       "       [ 22.,   1.,  67.,  23., 181.],\n",
       "       [ 23.,   1.,  85.,  37., 274.],\n",
       "       [ 24.,   1.,  55.,  40., 303.],\n",
       "       [ 25.,   1.,  63.,  30., 244.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "np.random.seed(7)\n",
    "data = np.genfromtxt(\"data/x09.txt\", skip_header = 36)  # 불러오는 함수\n",
    "# skip_header : 몇번째까지 건너뛸건지 \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([354., 190., 405., 263., 451., 302., 288., 385., 402., 365., 209.,\n",
       "       290., 346., 254., 395., 434., 220., 374., 308., 220., 311., 181.,\n",
       "       274., 303., 244.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 회귀 모델이여야 한다. x값이 여러개이기 때문\n",
    "# 텐서플로우에서는 되게 복잡하다. (그래프 작업)\n",
    "X = np.array(data[:, 2: 4], dtype=np.float32)\n",
    "y = np.array(data[:, 4], dtype=np.float32)\n",
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2, ))) # 레이어 추가 Dense() 입력과 출력을 묶는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    텐서플로우에서 가설공식을 세워서 찾아야 했지만.\n",
    "    \n",
    "    keras에서는 우리가 가설 세울 필요가없다.\n",
    "    \n",
    "    from keras.models import Sequential 을 사용하면 많은 가설공식을 사용할 수 있다.\n",
    "    from keras.layers.core import Dense\n",
    "    \n",
    "    텐서플로우의\n",
    "    \n",
    "        X1 = tf.placeholder(tf.float32, shape=[None])\n",
    "        X2 = tf.placeholder(tf.float32, shape=[None])\n",
    "        X3 = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "        y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "\n",
    "         가중치\n",
    "        W1 = tf.Variable(tf.random_normal([1]))\n",
    "        W2 = tf.Variable(tf.random_normal([1]))\n",
    "        W3 = tf.Variable(tf.random_normal([1]))\n",
    "        b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "\n",
    "         가설\n",
    "        hypothesis = W1*X1 + W2*X2 + W3*X3 + b\n",
    "\n",
    "    이 작업을 한줄로 끝낸 것이다.\n",
    "    \n",
    "    또 독립변수가 여러개라면 매트릭스로 처리한다. 그래서 shape을 정해줬었는데 \n",
    "    이 정보만 넘겨주면 된다. \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_shape=(2, ))) # 레이어 추가 \n",
    "        Dense() 입력과 출력을 묶는 함수\n",
    "            여기서는 출력이 1개이고 입력이  독립변수 2개 전체 데이터 갯수 26 개\n",
    "            Dense(1, input_shape=(2, 26)) 이렇게 써야하지만\n",
    "            생략해서 Dense(1, input_shape=(2, )) 이렇게 쓴다. \n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용처리 계산을 한번에 끝내는 함수 compile()\n",
    "model.compile(loss=\"mse\", optimizer= RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    비용은 알고리즘 마다 다른데 어떻게?\n",
    "    \n",
    "    loss옵션으로 어떤건지만 알려주면 된다. \n",
    "    \n",
    "    평균제곱 오차에 대한 옵션이 다 있다.\n",
    "    \n",
    "    loss=\"mse\" : Mean Square Error?\n",
    "    \n",
    "    \n",
    "    선형회귀에서 많이 쓰는 알고리즘\n",
    "    from keras.optimizers import RMSprop\n",
    "    optiminzer= RMSprop(lr=0.01)  : 뭐 다른 알고리즘을 써도 된다. lr은 learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    텐서플로우에서는 여기까지가 그래프 생성이었다.\n",
    "    그 후 run을 통해 실행시켰는데\n",
    "    \n",
    "    keras에서는 어떻게 바뀌었는지 봐보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 69871.0938\n",
      "Epoch 2/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 68076.3594\n",
      "Epoch 3/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 66797.8984\n",
      "Epoch 4/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 65741.3125\n",
      "Epoch 5/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 64813.5156\n",
      "Epoch 6/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 63971.3984\n",
      "Epoch 7/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 63191.0039\n",
      "Epoch 8/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 62457.4297\n",
      "Epoch 9/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 61760.7148\n",
      "Epoch 10/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 61093.8164\n",
      "Epoch 11/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 60451.5938\n",
      "Epoch 12/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 59830.1484\n",
      "Epoch 13/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 59226.4492\n",
      "Epoch 14/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 58638.0859\n",
      "Epoch 15/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 58063.1367\n",
      "Epoch 16/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 57499.9961\n",
      "Epoch 17/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 56947.3867\n",
      "Epoch 18/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 56404.2109\n",
      "Epoch 19/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 55869.5508\n",
      "Epoch 20/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 55342.6250\n",
      "Epoch 21/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 54822.7695\n",
      "Epoch 22/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 54309.4102\n",
      "Epoch 23/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 53802.0703\n",
      "Epoch 24/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 53300.3008\n",
      "Epoch 25/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 52803.7383\n",
      "Epoch 26/1000\n",
      "25/25 [==============================] - 0s 42us/step - loss: 52312.0547\n",
      "Epoch 27/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 51824.9688\n",
      "Epoch 28/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 51342.2305\n",
      "Epoch 29/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 50863.6094\n",
      "Epoch 30/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 50388.9219\n",
      "Epoch 31/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 49917.9883\n",
      "Epoch 32/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 49450.6562\n",
      "Epoch 33/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 48986.7891\n",
      "Epoch 34/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 48526.2812\n",
      "Epoch 35/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 48068.9961\n",
      "Epoch 36/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 47614.8633\n",
      "Epoch 37/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 47163.7852\n",
      "Epoch 38/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 46715.6914\n",
      "Epoch 39/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 46270.5117\n",
      "Epoch 40/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 45828.1758\n",
      "Epoch 41/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 45388.6406\n",
      "Epoch 42/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 44951.8594\n",
      "Epoch 43/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 44517.7734\n",
      "Epoch 44/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 44086.3594\n",
      "Epoch 45/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 43657.5742\n",
      "Epoch 46/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 43231.3906\n",
      "Epoch 47/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 42807.7656\n",
      "Epoch 48/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 42386.6914\n",
      "Epoch 49/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 41968.1289\n",
      "Epoch 50/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 41552.0781\n",
      "Epoch 51/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 41138.5000\n",
      "Epoch 52/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 40727.3906\n",
      "Epoch 53/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 40318.7266\n",
      "Epoch 54/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 39912.4961\n",
      "Epoch 55/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 39508.6875\n",
      "Epoch 56/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 39107.2930\n",
      "Epoch 57/1000\n",
      "25/25 [==============================] - 0s 80us/step - loss: 38708.2930\n",
      "Epoch 58/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 38311.6875\n",
      "Epoch 59/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 37917.4688\n",
      "Epoch 60/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 37525.6172\n",
      "Epoch 61/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 37136.1367\n",
      "Epoch 62/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 36749.0156\n",
      "Epoch 63/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 36364.2539\n",
      "Epoch 64/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 35981.8398\n",
      "Epoch 65/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 35601.7734\n",
      "Epoch 66/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 35224.0508\n",
      "Epoch 67/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 34848.6680\n",
      "Epoch 68/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 34475.6094\n",
      "Epoch 69/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 34104.8867\n",
      "Epoch 70/1000\n",
      "25/25 [==============================] - 0s 37us/step - loss: 33736.4883\n",
      "Epoch 71/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 33370.4141\n",
      "Epoch 72/1000\n",
      "25/25 [==============================] - 0s 43us/step - loss: 33006.6641\n",
      "Epoch 73/1000\n",
      "25/25 [==============================] - 0s 77us/step - loss: 32645.2305\n",
      "Epoch 74/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 32286.1133\n",
      "Epoch 75/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 31929.3047\n",
      "Epoch 76/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 31574.8184\n",
      "Epoch 77/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 31222.6367\n",
      "Epoch 78/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 30872.7656\n",
      "Epoch 79/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 30525.1973\n",
      "Epoch 80/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 30179.9395\n",
      "Epoch 81/1000\n",
      "25/25 [==============================] - 0s 37us/step - loss: 29836.9766\n",
      "Epoch 82/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 29496.3242\n",
      "Epoch 83/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 29157.9648\n",
      "Epoch 84/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 28821.9023\n",
      "Epoch 85/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 28488.1367\n",
      "Epoch 86/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 28156.6699\n",
      "Epoch 87/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 27827.4980\n",
      "Epoch 88/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 27500.6191\n",
      "Epoch 89/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 27176.0332\n",
      "Epoch 90/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 26853.7324\n",
      "Epoch 91/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 26533.7227\n",
      "Epoch 92/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 26215.9980\n",
      "Epoch 93/1000\n",
      "25/25 [==============================] - 0s 37us/step - loss: 25900.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 25587.4121\n",
      "Epoch 95/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 25276.5391\n",
      "Epoch 96/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 24967.9609\n",
      "Epoch 97/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 24661.6523\n",
      "Epoch 98/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 24357.6309\n",
      "Epoch 99/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 24055.8848\n",
      "Epoch 100/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 23756.4199\n",
      "Epoch 101/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 23459.2305\n",
      "Epoch 102/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 23164.3145\n",
      "Epoch 103/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 22871.6719\n",
      "Epoch 104/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 22581.3027\n",
      "Epoch 105/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 22293.2070\n",
      "Epoch 106/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 22007.3809\n",
      "Epoch 107/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 21723.8203\n",
      "Epoch 108/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 21442.5293\n",
      "Epoch 109/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 21163.5059\n",
      "Epoch 110/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 20886.7441\n",
      "Epoch 111/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 20612.2461\n",
      "Epoch 112/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 20340.0137\n",
      "Epoch 113/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 20070.0371\n",
      "Epoch 114/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 19802.3223\n",
      "Epoch 115/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 19536.8652\n",
      "Epoch 116/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 19273.6641\n",
      "Epoch 117/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 19012.7168\n",
      "Epoch 118/1000\n",
      "25/25 [==============================] - 0s 46us/step - loss: 18754.0234\n",
      "Epoch 119/1000\n",
      "25/25 [==============================] - 0s 34us/step - loss: 18497.5859\n",
      "Epoch 120/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 18243.3945\n",
      "Epoch 121/1000\n",
      "25/25 [==============================] - 0s 38us/step - loss: 17991.4512\n",
      "Epoch 122/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 17741.7559\n",
      "Epoch 123/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 17494.3086\n",
      "Epoch 124/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 17249.1016\n",
      "Epoch 125/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 17006.1387\n",
      "Epoch 126/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 16765.4141\n",
      "Epoch 127/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 16526.9336\n",
      "Epoch 128/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 16290.6865\n",
      "Epoch 129/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 16056.6777\n",
      "Epoch 130/1000\n",
      "25/25 [==============================] - 0s 42us/step - loss: 15824.9004\n",
      "Epoch 131/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 15595.3555\n",
      "Epoch 132/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 15368.0391\n",
      "Epoch 133/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 15142.9551\n",
      "Epoch 134/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 14920.0947\n",
      "Epoch 135/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 14699.4561\n",
      "Epoch 136/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 14481.0410\n",
      "Epoch 137/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 14264.8486\n",
      "Epoch 138/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 14050.8721\n",
      "Epoch 139/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 13839.1133\n",
      "Epoch 140/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 13629.5703\n",
      "Epoch 141/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 13422.2363\n",
      "Epoch 142/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 13217.1133\n",
      "Epoch 143/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 13014.1973\n",
      "Epoch 144/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 12813.4883\n",
      "Epoch 145/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 12614.9785\n",
      "Epoch 146/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 12418.6709\n",
      "Epoch 147/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 12224.5635\n",
      "Epoch 148/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 12032.6504\n",
      "Epoch 149/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 11842.9316\n",
      "Epoch 150/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 11655.4023\n",
      "Epoch 151/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 11470.0674\n",
      "Epoch 152/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 11286.9121\n",
      "Epoch 153/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 11105.9375\n",
      "Epoch 154/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 10927.1475\n",
      "Epoch 155/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 10750.5342\n",
      "Epoch 156/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 10576.0947\n",
      "Epoch 157/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 10403.8281\n",
      "Epoch 158/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 10233.7275\n",
      "Epoch 159/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 10065.7939\n",
      "Epoch 160/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 9900.0254\n",
      "Epoch 161/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 9736.4160\n",
      "Epoch 162/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 9574.9629\n",
      "Epoch 163/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 9415.6592\n",
      "Epoch 164/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 9258.5059\n",
      "Epoch 165/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 9103.5039\n",
      "Epoch 166/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 8950.6377\n",
      "Epoch 167/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 8799.9131\n",
      "Epoch 168/1000\n",
      "25/25 [==============================] - 0s 38us/step - loss: 8651.3271\n",
      "Epoch 169/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 8504.8691\n",
      "Epoch 170/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 8360.5410\n",
      "Epoch 171/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 8218.3330\n",
      "Epoch 172/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 8078.2476\n",
      "Epoch 173/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 7940.2812\n",
      "Epoch 174/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 7804.4238\n",
      "Epoch 175/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 7670.6724\n",
      "Epoch 176/1000\n",
      "25/25 [==============================] - 0s 81us/step - loss: 7539.0229\n",
      "Epoch 177/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 7409.4751\n",
      "Epoch 178/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 7282.0200\n",
      "Epoch 179/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 7156.6548\n",
      "Epoch 180/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 7033.3687\n",
      "Epoch 181/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 6912.1680\n",
      "Epoch 182/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 6793.0376\n",
      "Epoch 183/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 6675.9756\n",
      "Epoch 184/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 6560.9785\n",
      "Epoch 185/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 6448.0371\n",
      "Epoch 186/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 6337.1504\n",
      "Epoch 187/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 6228.3057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 6121.5044\n",
      "Epoch 189/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 6016.7368\n",
      "Epoch 190/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 5913.9951\n",
      "Epoch 191/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 5813.2754\n",
      "Epoch 192/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 5714.5708\n",
      "Epoch 193/1000\n",
      "25/25 [==============================] - 0s 37us/step - loss: 5617.8730\n",
      "Epoch 194/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 5523.1738\n",
      "Epoch 195/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 5430.4717\n",
      "Epoch 196/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 5339.7515\n",
      "Epoch 197/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 5251.0107\n",
      "Epoch 198/1000\n",
      "25/25 [==============================] - 0s 38us/step - loss: 5164.2373\n",
      "Epoch 199/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 5079.4292\n",
      "Epoch 200/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4996.5708\n",
      "Epoch 201/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4915.6572\n",
      "Epoch 202/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4836.6782\n",
      "Epoch 203/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4759.6230\n",
      "Epoch 204/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4684.4844\n",
      "Epoch 205/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4611.2529\n",
      "Epoch 206/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4539.9155\n",
      "Epoch 207/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4470.4600\n",
      "Epoch 208/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 4402.8799\n",
      "Epoch 209/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 4337.1626\n",
      "Epoch 210/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 4273.2954\n",
      "Epoch 211/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 4211.2637\n",
      "Epoch 212/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4151.0576\n",
      "Epoch 213/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 4092.6619\n",
      "Epoch 214/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 4036.0659\n",
      "Epoch 215/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3981.2512\n",
      "Epoch 216/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3928.2068\n",
      "Epoch 217/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3876.9133\n",
      "Epoch 218/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3827.3579\n",
      "Epoch 219/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3779.5237\n",
      "Epoch 220/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3733.3899\n",
      "Epoch 221/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3688.9431\n",
      "Epoch 222/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3646.1616\n",
      "Epoch 223/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3605.0244\n",
      "Epoch 224/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3565.5146\n",
      "Epoch 225/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3527.6082\n",
      "Epoch 226/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3491.2861\n",
      "Epoch 227/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3456.5222\n",
      "Epoch 228/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3423.2937\n",
      "Epoch 229/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 3391.5757\n",
      "Epoch 230/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 3361.3391\n",
      "Epoch 231/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3332.5591\n",
      "Epoch 232/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3305.2063\n",
      "Epoch 233/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3279.2507\n",
      "Epoch 234/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3254.6599\n",
      "Epoch 235/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3231.4014\n",
      "Epoch 236/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3209.4417\n",
      "Epoch 237/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3188.7434\n",
      "Epoch 238/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3169.2698\n",
      "Epoch 239/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3150.9824\n",
      "Epoch 240/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3133.8389\n",
      "Epoch 241/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3117.7971\n",
      "Epoch 242/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3102.8127\n",
      "Epoch 243/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3088.8394\n",
      "Epoch 244/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3075.8284\n",
      "Epoch 245/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3063.7302\n",
      "Epoch 246/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3052.4929\n",
      "Epoch 247/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 3042.0635\n",
      "Epoch 248/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3032.3850\n",
      "Epoch 249/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3023.4033\n",
      "Epoch 250/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3015.0591\n",
      "Epoch 251/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3007.2939\n",
      "Epoch 252/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 3000.0488\n",
      "Epoch 253/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2993.2634\n",
      "Epoch 254/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2986.8794\n",
      "Epoch 255/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2980.8367\n",
      "Epoch 256/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2975.0791\n",
      "Epoch 257/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2969.5505\n",
      "Epoch 258/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2964.1982\n",
      "Epoch 259/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2958.9731\n",
      "Epoch 260/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2953.8279\n",
      "Epoch 261/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2948.7229\n",
      "Epoch 262/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2943.6201\n",
      "Epoch 263/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2938.4888\n",
      "Epoch 264/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2933.3003\n",
      "Epoch 265/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2928.0349\n",
      "Epoch 266/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2922.6753\n",
      "Epoch 267/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2917.2078\n",
      "Epoch 268/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2911.6248\n",
      "Epoch 269/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2905.9216\n",
      "Epoch 270/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2900.0974\n",
      "Epoch 271/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2894.1514\n",
      "Epoch 272/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2888.0852\n",
      "Epoch 273/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2881.9043\n",
      "Epoch 274/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2875.6135\n",
      "Epoch 275/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2869.2180\n",
      "Epoch 276/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2862.7246\n",
      "Epoch 277/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2856.1406\n",
      "Epoch 278/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2849.4736\n",
      "Epoch 279/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2842.7300\n",
      "Epoch 280/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2835.9175\n",
      "Epoch 281/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2829.0425\n",
      "Epoch 282/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2822.1128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2815.1348\n",
      "Epoch 284/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2808.1157\n",
      "Epoch 285/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2801.0613\n",
      "Epoch 286/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2793.9768\n",
      "Epoch 287/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2786.8704\n",
      "Epoch 288/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2779.7437\n",
      "Epoch 289/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2772.6050\n",
      "Epoch 290/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2765.4568\n",
      "Epoch 291/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2758.3049\n",
      "Epoch 292/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2751.1526\n",
      "Epoch 293/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2744.0034\n",
      "Epoch 294/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2736.8613\n",
      "Epoch 295/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2729.7285\n",
      "Epoch 296/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2722.6084\n",
      "Epoch 297/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2715.5034\n",
      "Epoch 298/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2708.4163\n",
      "Epoch 299/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2701.3481\n",
      "Epoch 300/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2694.3018\n",
      "Epoch 301/1000\n",
      "25/25 [==============================] - 0s 80us/step - loss: 2687.2781\n",
      "Epoch 302/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2680.2791\n",
      "Epoch 303/1000\n",
      "25/25 [==============================] - 0s 80us/step - loss: 2673.3057\n",
      "Epoch 304/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2666.3594\n",
      "Epoch 305/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2659.4409\n",
      "Epoch 306/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2652.5513\n",
      "Epoch 307/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2645.6924\n",
      "Epoch 308/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2638.8625\n",
      "Epoch 309/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2632.0645\n",
      "Epoch 310/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2625.2976\n",
      "Epoch 311/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2618.5625\n",
      "Epoch 312/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2611.8596\n",
      "Epoch 313/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2605.1899\n",
      "Epoch 314/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2598.5527\n",
      "Epoch 315/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2591.9485\n",
      "Epoch 316/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2585.3777\n",
      "Epoch 317/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2578.8396\n",
      "Epoch 318/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2572.3362\n",
      "Epoch 319/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2565.8657\n",
      "Epoch 320/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 2559.4285\n",
      "Epoch 321/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2553.0244\n",
      "Epoch 322/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2546.6545\n",
      "Epoch 323/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2540.3179\n",
      "Epoch 324/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2534.0154\n",
      "Epoch 325/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2527.7454\n",
      "Epoch 326/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2521.5090\n",
      "Epoch 327/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2515.3066\n",
      "Epoch 328/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2509.1372\n",
      "Epoch 329/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2503.0010\n",
      "Epoch 330/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2496.8984\n",
      "Epoch 331/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2490.8279\n",
      "Epoch 332/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2484.7910\n",
      "Epoch 333/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2478.7866\n",
      "Epoch 334/1000\n",
      "25/25 [==============================] - 0s 80us/step - loss: 2472.8149\n",
      "Epoch 335/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2466.8762\n",
      "Epoch 336/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2460.9700\n",
      "Epoch 337/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2455.0967\n",
      "Epoch 338/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2449.2551\n",
      "Epoch 339/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2443.4456\n",
      "Epoch 340/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2437.6689\n",
      "Epoch 341/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2431.9243\n",
      "Epoch 342/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2426.2112\n",
      "Epoch 343/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2420.5305\n",
      "Epoch 344/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2414.8821\n",
      "Epoch 345/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2409.2646\n",
      "Epoch 346/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2403.6790\n",
      "Epoch 347/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2398.1255\n",
      "Epoch 348/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2392.6030\n",
      "Epoch 349/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2387.1121\n",
      "Epoch 350/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2381.6531\n",
      "Epoch 351/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2376.2251\n",
      "Epoch 352/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2370.8311\n",
      "Epoch 353/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2365.4812\n",
      "Epoch 354/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2360.2727\n",
      "Epoch 355/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2355.3306\n",
      "Epoch 356/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2350.7607\n",
      "Epoch 357/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2344.9272\n",
      "Epoch 358/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2339.6497\n",
      "Epoch 359/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2334.4900\n",
      "Epoch 360/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2329.4014\n",
      "Epoch 361/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2324.3354\n",
      "Epoch 362/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2319.2976\n",
      "Epoch 363/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2314.2793\n",
      "Epoch 364/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 2309.2861\n",
      "Epoch 365/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2304.3147\n",
      "Epoch 366/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2299.3687\n",
      "Epoch 367/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2294.4460\n",
      "Epoch 368/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2289.5500\n",
      "Epoch 369/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2284.6792\n",
      "Epoch 370/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2279.8374\n",
      "Epoch 371/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2275.0205\n",
      "Epoch 372/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2270.2363\n",
      "Epoch 373/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2265.4824\n",
      "Epoch 374/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2260.7815\n",
      "Epoch 375/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2256.1348\n",
      "Epoch 376/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2251.6499\n",
      "Epoch 377/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2247.1030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2242.6331\n",
      "Epoch 379/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2237.9282\n",
      "Epoch 380/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2233.3674\n",
      "Epoch 381/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2228.8267\n",
      "Epoch 382/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2224.3601\n",
      "Epoch 383/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2219.9138\n",
      "Epoch 384/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2215.5073\n",
      "Epoch 385/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2211.1191\n",
      "Epoch 386/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2206.7639\n",
      "Epoch 387/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2202.4290\n",
      "Epoch 388/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2198.1277\n",
      "Epoch 389/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2193.8484\n",
      "Epoch 390/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2189.6094\n",
      "Epoch 391/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2185.3950\n",
      "Epoch 392/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2181.2424\n",
      "Epoch 393/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2177.1091\n",
      "Epoch 394/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2173.0691\n",
      "Epoch 395/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2168.9780\n",
      "Epoch 396/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2164.9656\n",
      "Epoch 397/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2160.8787\n",
      "Epoch 398/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2156.8745\n",
      "Epoch 399/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2152.8638\n",
      "Epoch 400/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2148.9175\n",
      "Epoch 401/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2144.9829\n",
      "Epoch 402/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2141.0962\n",
      "Epoch 403/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2137.2236\n",
      "Epoch 404/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2133.3938\n",
      "Epoch 405/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2129.5796\n",
      "Epoch 406/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2125.8103\n",
      "Epoch 407/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2122.0571\n",
      "Epoch 408/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2118.3574\n",
      "Epoch 409/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2114.6677\n",
      "Epoch 410/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2111.0466\n",
      "Epoch 411/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2107.4126\n",
      "Epoch 412/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2103.8513\n",
      "Epoch 413/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2100.2559\n",
      "Epoch 414/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2096.7305\n",
      "Epoch 415/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2093.1860\n",
      "Epoch 416/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2089.7065\n",
      "Epoch 417/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2086.2266\n",
      "Epoch 418/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2082.8018\n",
      "Epoch 419/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2079.3853\n",
      "Epoch 420/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2076.0181\n",
      "Epoch 421/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2072.6621\n",
      "Epoch 422/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2069.3545\n",
      "Epoch 423/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2066.0576\n",
      "Epoch 424/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2062.8140\n",
      "Epoch 425/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2059.5762\n",
      "Epoch 426/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2056.3982\n",
      "Epoch 427/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2053.2163\n",
      "Epoch 428/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2050.0986\n",
      "Epoch 429/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2046.9664\n",
      "Epoch 430/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2043.8990\n",
      "Epoch 431/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2040.8187\n",
      "Epoch 432/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2037.8000\n",
      "Epoch 433/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2034.7764\n",
      "Epoch 434/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2031.8109\n",
      "Epoch 435/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2028.8473\n",
      "Epoch 436/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2025.9380\n",
      "Epoch 437/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2023.0337\n",
      "Epoch 438/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2020.1820\n",
      "Epoch 439/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2017.3361\n",
      "Epoch 440/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 2014.5448\n",
      "Epoch 441/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2011.7560\n",
      "Epoch 442/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2009.0251\n",
      "Epoch 443/1000\n",
      "25/25 [==============================] - 0s 80us/step - loss: 2006.2919\n",
      "Epoch 444/1000\n",
      "25/25 [==============================] - 0s 80us/step - loss: 2003.6196\n",
      "Epoch 445/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 2000.9398\n",
      "Epoch 446/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1998.3210\n",
      "Epoch 447/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1995.6941\n",
      "Epoch 448/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1993.1268\n",
      "Epoch 449/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1990.5552\n",
      "Epoch 450/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1988.0413\n",
      "Epoch 451/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1985.5269\n",
      "Epoch 452/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1983.0675\n",
      "Epoch 453/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1980.6097\n",
      "Epoch 454/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1978.2069\n",
      "Epoch 455/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1975.8064\n",
      "Epoch 456/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1973.4606\n",
      "Epoch 457/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1971.1157\n",
      "Epoch 458/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1968.8278\n",
      "Epoch 459/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1966.5381\n",
      "Epoch 460/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1964.3069\n",
      "Epoch 461/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1962.0709\n",
      "Epoch 462/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1959.8931\n",
      "Epoch 463/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1957.7102\n",
      "Epoch 464/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1955.5858\n",
      "Epoch 465/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1953.4572\n",
      "Epoch 466/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1951.3853\n",
      "Epoch 467/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1949.3113\n",
      "Epoch 468/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1947.2931\n",
      "Epoch 469/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1945.2742\n",
      "Epoch 470/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1943.3113\n",
      "Epoch 471/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1941.3470\n",
      "Epoch 472/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1939.4391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1937.5300\n",
      "Epoch 474/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1935.6770\n",
      "Epoch 475/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1933.8215\n",
      "Epoch 476/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1932.0228\n",
      "Epoch 477/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1930.2206\n",
      "Epoch 478/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1928.4747\n",
      "Epoch 479/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1926.7253\n",
      "Epoch 480/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1925.0316\n",
      "Epoch 481/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1923.3347\n",
      "Epoch 482/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1921.6936\n",
      "Epoch 483/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1920.0491\n",
      "Epoch 484/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1918.4603\n",
      "Epoch 485/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1916.8688\n",
      "Epoch 486/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1915.3326\n",
      "Epoch 487/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1913.7942\n",
      "Epoch 488/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1912.3103\n",
      "Epoch 489/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1910.8243\n",
      "Epoch 490/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1909.3938\n",
      "Epoch 491/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1907.9595\n",
      "Epoch 492/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1906.5806\n",
      "Epoch 493/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1905.1980\n",
      "Epoch 494/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1903.8704\n",
      "Epoch 495/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1902.5380\n",
      "Epoch 496/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1901.2610\n",
      "Epoch 497/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1899.9789\n",
      "Epoch 498/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1898.7522\n",
      "Epoch 499/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1897.5203\n",
      "Epoch 500/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1896.3434\n",
      "Epoch 501/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1895.1626\n",
      "Epoch 502/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1894.0350\n",
      "Epoch 503/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1892.9044\n",
      "Epoch 504/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1891.8265\n",
      "Epoch 505/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1890.7446\n",
      "Epoch 506/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1889.7164\n",
      "Epoch 507/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1888.6837\n",
      "Epoch 508/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1887.7042\n",
      "Epoch 509/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1886.7195\n",
      "Epoch 510/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1885.7875\n",
      "Epoch 511/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1884.8505\n",
      "Epoch 512/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1883.9653\n",
      "Epoch 513/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1883.0757\n",
      "Epoch 514/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1882.2368\n",
      "Epoch 515/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1881.3929\n",
      "Epoch 516/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1880.6003\n",
      "Epoch 517/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1879.8030\n",
      "Epoch 518/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1879.0563\n",
      "Epoch 519/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1878.3037\n",
      "Epoch 520/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1877.6021\n",
      "Epoch 521/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1876.8936\n",
      "Epoch 522/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1876.2355\n",
      "Epoch 523/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1875.5713\n",
      "Epoch 524/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1874.9564\n",
      "Epoch 525/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1874.3352\n",
      "Epoch 526/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1873.7616\n",
      "Epoch 527/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1873.1818\n",
      "Epoch 528/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1872.6489\n",
      "Epoch 529/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1872.1099\n",
      "Epoch 530/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1871.6172\n",
      "Epoch 531/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1871.1179\n",
      "Epoch 532/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1870.6630\n",
      "Epoch 533/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1870.2021\n",
      "Epoch 534/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1869.7850\n",
      "Epoch 535/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1869.3615\n",
      "Epoch 536/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1868.9803\n",
      "Epoch 537/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1868.5917\n",
      "Epoch 538/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1868.2454\n",
      "Epoch 539/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1867.8916\n",
      "Epoch 540/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1867.5764\n",
      "Epoch 541/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1867.2550\n",
      "Epoch 542/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1866.9703\n",
      "Epoch 543/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1866.6792\n",
      "Epoch 544/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1866.4224\n",
      "Epoch 545/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1866.1600\n",
      "Epoch 546/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1865.9293\n",
      "Epoch 547/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1865.6938\n",
      "Epoch 548/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1865.4872\n",
      "Epoch 549/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1865.2758\n",
      "Epoch 550/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1865.0903\n",
      "Epoch 551/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1864.9009\n",
      "Epoch 552/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1864.7355\n",
      "Epoch 553/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1864.5660\n",
      "Epoch 554/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1864.4174\n",
      "Epoch 555/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1864.2651\n",
      "Epoch 556/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1864.1323\n",
      "Epoch 557/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1863.9954\n",
      "Epoch 558/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1863.8756\n",
      "Epoch 559/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1863.7528\n",
      "Epoch 560/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1863.6440\n",
      "Epoch 561/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1863.5334\n",
      "Epoch 562/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1863.4348\n",
      "Epoch 563/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1863.3344\n",
      "Epoch 564/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1863.2440\n",
      "Epoch 565/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1863.1534\n",
      "Epoch 566/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1863.0704\n",
      "Epoch 567/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1862.9111\n",
      "Epoch 569/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1862.8341\n",
      "Epoch 570/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.7635\n",
      "Epoch 571/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.6920\n",
      "Epoch 572/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.6268\n",
      "Epoch 573/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.5598\n",
      "Epoch 574/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1862.4978\n",
      "Epoch 575/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1862.4352\n",
      "Epoch 576/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.3772\n",
      "Epoch 577/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.3175\n",
      "Epoch 578/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1862.2627\n",
      "Epoch 579/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1862.2064\n",
      "Epoch 580/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1862.1539\n",
      "Epoch 581/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1862.0997\n",
      "Epoch 582/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1862.0493\n",
      "Epoch 583/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.9971\n",
      "Epoch 584/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.9482\n",
      "Epoch 585/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.8984\n",
      "Epoch 586/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.8514\n",
      "Epoch 587/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.8030\n",
      "Epoch 588/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.7563\n",
      "Epoch 589/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.7091\n",
      "Epoch 590/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.6647\n",
      "Epoch 591/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.6184\n",
      "Epoch 592/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.5746\n",
      "Epoch 593/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.5289\n",
      "Epoch 594/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.4862\n",
      "Epoch 595/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.4410\n",
      "Epoch 596/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.3992\n",
      "Epoch 597/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.3555\n",
      "Epoch 598/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.3136\n",
      "Epoch 599/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 1861.2699\n",
      "Epoch 600/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1861.2288\n",
      "Epoch 601/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.1854\n",
      "Epoch 602/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.1450\n",
      "Epoch 603/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.1025\n",
      "Epoch 604/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.0610\n",
      "Epoch 605/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1861.0199\n",
      "Epoch 606/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.9794\n",
      "Epoch 607/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.9375\n",
      "Epoch 608/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.8977\n",
      "Epoch 609/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.8560\n",
      "Epoch 610/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.8159\n",
      "Epoch 611/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 1860.7744\n",
      "Epoch 612/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.7351\n",
      "Epoch 613/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.6938\n",
      "Epoch 614/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.6545\n",
      "Epoch 615/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.6133\n",
      "Epoch 616/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.5741\n",
      "Epoch 617/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.5328\n",
      "Epoch 618/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.4939\n",
      "Epoch 619/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1860.4526\n",
      "Epoch 620/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.4133\n",
      "Epoch 621/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.3733\n",
      "Epoch 622/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.3344\n",
      "Epoch 623/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.2935\n",
      "Epoch 624/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.2545\n",
      "Epoch 625/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.2137\n",
      "Epoch 626/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.1750\n",
      "Epoch 627/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.1346\n",
      "Epoch 628/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.0962\n",
      "Epoch 629/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1860.0548\n",
      "Epoch 630/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1860.0164\n",
      "Epoch 631/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.9761\n",
      "Epoch 632/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.9371\n",
      "Epoch 633/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.8972\n",
      "Epoch 634/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.8583\n",
      "Epoch 635/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.8176\n",
      "Epoch 636/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.7789\n",
      "Epoch 637/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.7393\n",
      "Epoch 638/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.7007\n",
      "Epoch 639/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.6602\n",
      "Epoch 640/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.6217\n",
      "Epoch 641/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.5813\n",
      "Epoch 642/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.5431\n",
      "Epoch 643/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.5024\n",
      "Epoch 644/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.4642\n",
      "Epoch 645/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.4237\n",
      "Epoch 646/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.3860\n",
      "Epoch 647/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.3453\n",
      "Epoch 648/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.3070\n",
      "Epoch 649/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1859.2667\n",
      "Epoch 650/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.2281\n",
      "Epoch 651/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.1881\n",
      "Epoch 652/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.1499\n",
      "Epoch 653/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.1099\n",
      "Epoch 654/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.0714\n",
      "Epoch 655/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1859.0309\n",
      "Epoch 656/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1858.9929\n",
      "Epoch 657/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.9525\n",
      "Epoch 658/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.9142\n",
      "Epoch 659/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.8749\n",
      "Epoch 660/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1858.8363\n",
      "Epoch 661/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1858.7958\n",
      "Epoch 662/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.7579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.7177\n",
      "Epoch 664/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.6796\n",
      "Epoch 665/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.6390\n",
      "Epoch 666/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.6010\n",
      "Epoch 667/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.5604\n",
      "Epoch 668/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.5225\n",
      "Epoch 669/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.4823\n",
      "Epoch 670/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.4446\n",
      "Epoch 671/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.4042\n",
      "Epoch 672/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1858.3665\n",
      "Epoch 673/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1858.3260\n",
      "Epoch 674/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1858.2878\n",
      "Epoch 675/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.2484\n",
      "Epoch 676/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1858.2098\n",
      "Epoch 677/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.1698\n",
      "Epoch 678/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.1318\n",
      "Epoch 679/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.0913\n",
      "Epoch 680/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.0532\n",
      "Epoch 681/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1858.0133\n",
      "Epoch 682/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.9753\n",
      "Epoch 683/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.9353\n",
      "Epoch 684/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.8972\n",
      "Epoch 685/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.8575\n",
      "Epoch 686/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.8191\n",
      "Epoch 687/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.7789\n",
      "Epoch 688/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.7412\n",
      "Epoch 689/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.7008\n",
      "Epoch 690/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1857.6631\n",
      "Epoch 691/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1857.6233\n",
      "Epoch 692/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1857.5852\n",
      "Epoch 693/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.5454\n",
      "Epoch 694/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.5077\n",
      "Epoch 695/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.4670\n",
      "Epoch 696/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.4296\n",
      "Epoch 697/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.3895\n",
      "Epoch 698/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1857.3511\n",
      "Epoch 699/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.3119\n",
      "Epoch 700/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.2734\n",
      "Epoch 701/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1857.2336\n",
      "Epoch 702/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1857.1957\n",
      "Epoch 703/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1857.1559\n",
      "Epoch 704/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.1179\n",
      "Epoch 705/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.0785\n",
      "Epoch 706/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.0402\n",
      "Epoch 707/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1857.0000\n",
      "Epoch 708/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.9620\n",
      "Epoch 709/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.9224\n",
      "Epoch 710/1000\n",
      "25/25 [==============================] - 0s 41us/step - loss: 1856.8844\n",
      "Epoch 711/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1856.8442\n",
      "Epoch 712/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.8068\n",
      "Epoch 713/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.7668\n",
      "Epoch 714/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.7288\n",
      "Epoch 715/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.6891\n",
      "Epoch 716/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.6512\n",
      "Epoch 717/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.6116\n",
      "Epoch 718/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.5736\n",
      "Epoch 719/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.5333\n",
      "Epoch 720/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.4957\n",
      "Epoch 721/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.4559\n",
      "Epoch 722/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.4186\n",
      "Epoch 723/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.3784\n",
      "Epoch 724/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.3406\n",
      "Epoch 725/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.3007\n",
      "Epoch 726/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.2632\n",
      "Epoch 727/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.2230\n",
      "Epoch 728/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1856.1857\n",
      "Epoch 729/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.1460\n",
      "Epoch 730/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.1077\n",
      "Epoch 731/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.0680\n",
      "Epoch 732/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1856.0308\n",
      "Epoch 733/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.9904\n",
      "Epoch 734/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.9530\n",
      "Epoch 735/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.9130\n",
      "Epoch 736/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.8756\n",
      "Epoch 737/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.8356\n",
      "Epoch 738/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.7981\n",
      "Epoch 739/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.7579\n",
      "Epoch 740/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.7205\n",
      "Epoch 741/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.6803\n",
      "Epoch 742/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.6428\n",
      "Epoch 743/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.6031\n",
      "Epoch 744/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.5653\n",
      "Epoch 745/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.5259\n",
      "Epoch 746/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.4886\n",
      "Epoch 747/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.4486\n",
      "Epoch 748/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.4109\n",
      "Epoch 749/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.3717\n",
      "Epoch 750/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.3339\n",
      "Epoch 751/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.2939\n",
      "Epoch 752/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1855.2563\n",
      "Epoch 753/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.2167\n",
      "Epoch 754/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.1791\n",
      "Epoch 755/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.1392\n",
      "Epoch 756/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.1022\n",
      "Epoch 757/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1855.0245\n",
      "Epoch 759/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.9849\n",
      "Epoch 760/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.9470\n",
      "Epoch 761/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.9072\n",
      "Epoch 762/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.8700\n",
      "Epoch 763/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1854.8304\n",
      "Epoch 764/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.7930\n",
      "Epoch 765/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.7533\n",
      "Epoch 766/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1854.7159\n",
      "Epoch 767/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.6763\n",
      "Epoch 768/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.6388\n",
      "Epoch 769/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.5994\n",
      "Epoch 770/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1854.5619\n",
      "Epoch 771/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1854.5227\n",
      "Epoch 772/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1854.4847\n",
      "Epoch 773/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1854.4452\n",
      "Epoch 774/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.4078\n",
      "Epoch 775/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.3677\n",
      "Epoch 776/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.3306\n",
      "Epoch 777/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.2911\n",
      "Epoch 778/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.2532\n",
      "Epoch 779/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.2139\n",
      "Epoch 780/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.1763\n",
      "Epoch 781/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.1367\n",
      "Epoch 782/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1854.0997\n",
      "Epoch 783/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.0602\n",
      "Epoch 784/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1854.0225\n",
      "Epoch 785/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.9829\n",
      "Epoch 786/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.9459\n",
      "Epoch 787/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.9062\n",
      "Epoch 788/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.8684\n",
      "Epoch 789/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.8293\n",
      "Epoch 790/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.7914\n",
      "Epoch 791/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1853.7527\n",
      "Epoch 792/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.7152\n",
      "Epoch 793/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.6752\n",
      "Epoch 794/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.6382\n",
      "Epoch 795/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.5991\n",
      "Epoch 796/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.5610\n",
      "Epoch 797/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.5220\n",
      "Epoch 798/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.4843\n",
      "Epoch 799/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.4448\n",
      "Epoch 800/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.4080\n",
      "Epoch 801/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.3684\n",
      "Epoch 802/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.3309\n",
      "Epoch 803/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.2915\n",
      "Epoch 804/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.2544\n",
      "Epoch 805/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.2148\n",
      "Epoch 806/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.1776\n",
      "Epoch 807/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1853.1383\n",
      "Epoch 808/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.1010\n",
      "Epoch 809/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.0615\n",
      "Epoch 810/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1853.0244\n",
      "Epoch 811/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.9847\n",
      "Epoch 812/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.9478\n",
      "Epoch 813/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.9084\n",
      "Epoch 814/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.8711\n",
      "Epoch 815/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.8315\n",
      "Epoch 816/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.7944\n",
      "Epoch 817/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.7554\n",
      "Epoch 818/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.7178\n",
      "Epoch 819/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.6785\n",
      "Epoch 820/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.6417\n",
      "Epoch 821/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.6025\n",
      "Epoch 822/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.5649\n",
      "Epoch 823/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.5251\n",
      "Epoch 824/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.4883\n",
      "Epoch 825/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.4492\n",
      "Epoch 826/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.4117\n",
      "Epoch 827/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.3728\n",
      "Epoch 828/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.3358\n",
      "Epoch 829/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.2965\n",
      "Epoch 830/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.2589\n",
      "Epoch 831/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.2197\n",
      "Epoch 832/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1852.1826\n",
      "Epoch 833/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.1434\n",
      "Epoch 834/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.1064\n",
      "Epoch 835/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.0670\n",
      "Epoch 836/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1852.0298\n",
      "Epoch 837/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.9915\n",
      "Epoch 838/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.9532\n",
      "Epoch 839/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.9144\n",
      "Epoch 840/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.8773\n",
      "Epoch 841/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.8383\n",
      "Epoch 842/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.8013\n",
      "Epoch 843/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.7616\n",
      "Epoch 844/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.7247\n",
      "Epoch 845/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.6858\n",
      "Epoch 846/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.6486\n",
      "Epoch 847/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.6094\n",
      "Epoch 848/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.5721\n",
      "Epoch 849/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.5333\n",
      "Epoch 850/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.4962\n",
      "Epoch 851/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.4565\n",
      "Epoch 852/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.4203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.3806\n",
      "Epoch 854/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.3434\n",
      "Epoch 855/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.3051\n",
      "Epoch 856/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.2678\n",
      "Epoch 857/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.2286\n",
      "Epoch 858/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.1915\n",
      "Epoch 859/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.1525\n",
      "Epoch 860/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.1154\n",
      "Epoch 861/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.0765\n",
      "Epoch 862/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1851.0389\n",
      "Epoch 863/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1851.0000\n",
      "Epoch 864/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.9634\n",
      "Epoch 865/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.9243\n",
      "Epoch 866/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.8872\n",
      "Epoch 867/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.8480\n",
      "Epoch 868/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.8110\n",
      "Epoch 869/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.7723\n",
      "Epoch 870/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.7355\n",
      "Epoch 871/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.6963\n",
      "Epoch 872/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.6597\n",
      "Epoch 873/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.6200\n",
      "Epoch 874/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.5833\n",
      "Epoch 875/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.5442\n",
      "Epoch 876/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.5077\n",
      "Epoch 877/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.4686\n",
      "Epoch 878/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.4318\n",
      "Epoch 879/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.3925\n",
      "Epoch 880/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1850.3560\n",
      "Epoch 881/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.3169\n",
      "Epoch 882/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.2802\n",
      "Epoch 883/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.2407\n",
      "Epoch 884/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.2043\n",
      "Epoch 885/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.1652\n",
      "Epoch 886/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.1283\n",
      "Epoch 887/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.0895\n",
      "Epoch 888/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1850.0529\n",
      "Epoch 889/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1850.0139\n",
      "Epoch 890/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.9767\n",
      "Epoch 891/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.9381\n",
      "Epoch 892/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.9009\n",
      "Epoch 893/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.8618\n",
      "Epoch 894/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.8250\n",
      "Epoch 895/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.7864\n",
      "Epoch 896/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.7499\n",
      "Epoch 897/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.7111\n",
      "Epoch 898/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.6742\n",
      "Epoch 899/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.6351\n",
      "Epoch 900/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.5983\n",
      "Epoch 901/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.5593\n",
      "Epoch 902/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.5225\n",
      "Epoch 903/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.4838\n",
      "Epoch 904/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.4470\n",
      "Epoch 905/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.4083\n",
      "Epoch 906/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.3716\n",
      "Epoch 907/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.3330\n",
      "Epoch 908/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1849.2959\n",
      "Epoch 909/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.2572\n",
      "Epoch 910/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.2205\n",
      "Epoch 911/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1849.1819\n",
      "Epoch 912/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.1447\n",
      "Epoch 913/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.1064\n",
      "Epoch 914/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.0697\n",
      "Epoch 915/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1849.0309\n",
      "Epoch 916/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.9943\n",
      "Epoch 917/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.9554\n",
      "Epoch 918/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.9187\n",
      "Epoch 919/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1848.8800\n",
      "Epoch 920/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1848.8431\n",
      "Epoch 921/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1848.8048\n",
      "Epoch 922/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1848.7679\n",
      "Epoch 923/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.7290\n",
      "Epoch 924/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.6925\n",
      "Epoch 925/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.6539\n",
      "Epoch 926/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.6173\n",
      "Epoch 927/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.5787\n",
      "Epoch 928/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.5419\n",
      "Epoch 929/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.5034\n",
      "Epoch 930/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.4666\n",
      "Epoch 931/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.4282\n",
      "Epoch 932/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.3914\n",
      "Epoch 933/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.3523\n",
      "Epoch 934/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.3160\n",
      "Epoch 935/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1848.2777\n",
      "Epoch 936/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.2410\n",
      "Epoch 937/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.2019\n",
      "Epoch 938/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.1653\n",
      "Epoch 939/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.1273\n",
      "Epoch 940/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1848.0903\n",
      "Epoch 941/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1848.0515\n",
      "Epoch 942/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1848.0151\n",
      "Epoch 943/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.9766\n",
      "Epoch 944/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.9403\n",
      "Epoch 945/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.9016\n",
      "Epoch 946/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.8649\n",
      "Epoch 947/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.8264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.7898\n",
      "Epoch 949/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.7516\n",
      "Epoch 950/1000\n",
      "25/25 [==============================] - 0s 39us/step - loss: 1847.7148\n",
      "Epoch 951/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.6758\n",
      "Epoch 952/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.6395\n",
      "Epoch 953/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.6014\n",
      "Epoch 954/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.5648\n",
      "Epoch 955/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.5261\n",
      "Epoch 956/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.4901\n",
      "Epoch 957/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.4513\n",
      "Epoch 958/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.4148\n",
      "Epoch 959/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.3760\n",
      "Epoch 960/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.3397\n",
      "Epoch 961/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.3014\n",
      "Epoch 962/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.2649\n",
      "Epoch 963/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.2264\n",
      "Epoch 964/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.1899\n",
      "Epoch 965/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.1517\n",
      "Epoch 966/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.1150\n",
      "Epoch 967/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1847.0764\n",
      "Epoch 968/1000\n",
      "25/25 [==============================] - 0s 80us/step - loss: 1847.0402\n",
      "Epoch 969/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1847.0016\n",
      "Epoch 970/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.9652\n",
      "Epoch 971/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.9269\n",
      "Epoch 972/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.8903\n",
      "Epoch 973/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.8519\n",
      "Epoch 974/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.8160\n",
      "Epoch 975/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.7772\n",
      "Epoch 976/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.7407\n",
      "Epoch 977/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.7026\n",
      "Epoch 978/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.6661\n",
      "Epoch 979/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.6277\n",
      "Epoch 980/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.5911\n",
      "Epoch 981/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.5531\n",
      "Epoch 982/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.5168\n",
      "Epoch 983/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.4784\n",
      "Epoch 984/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.4418\n",
      "Epoch 985/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.4038\n",
      "Epoch 986/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.3676\n",
      "Epoch 987/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.3287\n",
      "Epoch 988/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.2931\n",
      "Epoch 989/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.2544\n",
      "Epoch 990/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.2178\n",
      "Epoch 991/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.1796\n",
      "Epoch 992/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.1436\n",
      "Epoch 993/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.1050\n",
      "Epoch 994/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1846.0688\n",
      "Epoch 995/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1846.0306\n",
      "Epoch 996/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1845.9945\n",
      "Epoch 997/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1845.9558\n",
      "Epoch 998/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1845.9197\n",
      "Epoch 999/1000\n",
      "25/25 [==============================] - 0s 0us/step - loss: 1845.8817\n",
      "Epoch 1000/1000\n",
      "25/25 [==============================] - 0s 40us/step - loss: 1845.8450\n"
     ]
    }
   ],
   "source": [
    "# 훈련 실행\n",
    "hist = model.fit(X, y, epochs=1000)  #입력, 출력, 반복횟수(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    비용이 줄어듬을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3c6e55988>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(hist.history.keys())\n",
    "# print(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    최소비용의 값을 loss가 가지고 있음\n",
    "    그래서 loss를 그래프로 그려서 확인해보자\n",
    "    \n",
    "    그래프를 통하여 감소됨을 확인되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측\n",
    "\n",
    "    체중이 100이고 나이가 40일때 혈당은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[350.51718]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict 함수\n",
    "model.predict(np.array([100, 40]).reshape(1, 2))  \n",
    "# 차원을 맞춰야한다. 행과열의 갯수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    이 사람의 혈당은 350이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1939979]\n",
      " [5.5435057]] [9.377161]\n"
     ]
    }
   ],
   "source": [
    "# 가중치, 절편 회귀선 확인\n",
    "w, b = model.get_weights()\n",
    "\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    가중치(2,1)와 절편(1,1)값이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습2. 주택가격 예측(회귀분석)\n",
    "\n",
    "    boston 집값 데이터   \n",
    "    from keras.datasets  ->   keras 관련 데이터셋들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()  #훈련용, 테스트용을 튜플로 받아올수있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n",
      "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)\n",
    "print(train_targets[0:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리(정규화)\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    입력값은 404개\n",
    "    결과값은 1개이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential 준비 \n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(train_data.shape[1], ), activation = \"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\")) \n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    입력갯수 출력갯수를 정해준다\n",
    "    \n",
    "    layer를 두개로 할 것이기 때문에 출력에 주의 한다.\n",
    "    \n",
    "    \n",
    "    layer1\n",
    "        model.add(Dense(64, input_shape=(train_data.shape[1], ), activation = \"relu\")) \n",
    "            model.add(64개출력, 독립변수 13개 전체 데이터 갯수 404개\n",
    "            train_data.shape[1]라고 하는게 좀 더 융통성이 생긴다. \n",
    "\n",
    "        activation : 알고리즘 선택 옵션 (sigmoid, ReLU 같은 알고리즘)\n",
    "    \n",
    "    \n",
    "    layer2\n",
    "        model.add(Dense(64, activation=\"relu\")) \n",
    "            얘는 자동으로 layer1의 출력을 입력값으로 받기 때문에 안써도 된다.\n",
    "            activation은 또 ReLU를 사용.   (다른 알고리즘을 사용해도 된다.)\n",
    "\n",
    "\n",
    "    layer3\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "            이때는 마지막이므로 출력값을 최종 출력값으로 써준다.\n",
    "            그리고 입력값을 안써도 된다. \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics =[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    metrics\n",
    "    mae : 평균 절대 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "404/404 [==============================] - 0s 750us/step - loss: 212.1958 - mae: 10.4754\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 669us/step - loss: 24.2042 - mae: 3.2455\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 647us/step - loss: 17.7237 - mae: 2.8084\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 627us/step - loss: 16.1173 - mae: 2.6054\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 659us/step - loss: 13.9749 - mae: 2.5144\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 681us/step - loss: 13.2786 - mae: 2.4419\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 13.0436 - mae: 2.3778\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 687us/step - loss: 11.8368 - mae: 2.3204\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 11.9129 - mae: 2.2257\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 632us/step - loss: 11.3262 - mae: 2.2476\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 625us/step - loss: 10.6369 - mae: 2.1949\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 642us/step - loss: 10.5047 - mae: 2.1594\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 622us/step - loss: 9.8721 - mae: 2.0869\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 625us/step - loss: 10.2396 - mae: 2.1207\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 642us/step - loss: 9.7416 - mae: 2.0304\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 615us/step - loss: 9.5950 - mae: 2.0020\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 617us/step - loss: 9.4835 - mae: 2.0180\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 627us/step - loss: 8.8264 - mae: 1.9494\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 605us/step - loss: 9.1012 - mae: 1.9548\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 617us/step - loss: 8.7297 - mae: 1.9134\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 634us/step - loss: 8.2618 - mae: 1.9405\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 634us/step - loss: 8.6759 - mae: 1.8891\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 684us/step - loss: 8.8157 - mae: 1.9482\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 642us/step - loss: 8.4090 - mae: 1.8838\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 632us/step - loss: 8.2547 - mae: 1.8493\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 632us/step - loss: 7.8146 - mae: 1.8676\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 657us/step - loss: 7.9857 - mae: 1.8575\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 691us/step - loss: 8.0391 - mae: 1.8275\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 716us/step - loss: 7.8233 - mae: 1.8276\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 689us/step - loss: 7.5859 - mae: 1.8269\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 662us/step - loss: 7.1651 - mae: 1.7355\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 669us/step - loss: 7.4336 - mae: 1.7556\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 7.2348 - mae: 1.7445\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 677us/step - loss: 6.9943 - mae: 1.7226\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 7.0489 - mae: 1.8033\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 684us/step - loss: 6.6423 - mae: 1.7341\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 681us/step - loss: 7.1054 - mae: 1.7517\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 686us/step - loss: 6.8889 - mae: 1.7543\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 681us/step - loss: 7.0908 - mae: 1.6660\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 689us/step - loss: 6.9796 - mae: 1.7318\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 686us/step - loss: 6.7884 - mae: 1.6743\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 681us/step - loss: 6.8063 - mae: 1.6582\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 689us/step - loss: 6.4549 - mae: 1.6429\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 689us/step - loss: 6.1112 - mae: 1.6686\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 691us/step - loss: 6.5045 - mae: 1.6852\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 6.2635 - mae: 1.6187\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 644us/step - loss: 6.5571 - mae: 1.6455\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 617us/step - loss: 6.4329 - mae: 1.6703\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 622us/step - loss: 6.1938 - mae: 1.6364\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 672us/step - loss: 6.4299 - mae: 1.6240\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 6.1063 - mae: 1.6443\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 674us/step - loss: 5.9749 - mae: 1.5817\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 662us/step - loss: 5.9079 - mae: 1.5641\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 689us/step - loss: 5.6223 - mae: 1.6050\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 634us/step - loss: 5.7149 - mae: 1.6050\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 617us/step - loss: 5.9550 - mae: 1.6170\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 617us/step - loss: 5.7396 - mae: 1.5627\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 649us/step - loss: 5.9059 - mae: 1.5970\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 681us/step - loss: 5.8257 - mae: 1.5757\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 681us/step - loss: 5.6462 - mae: 1.5684\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 686us/step - loss: 5.8578 - mae: 1.6121\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 676us/step - loss: 5.5750 - mae: 1.5356\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 662us/step - loss: 5.6971 - mae: 1.5831\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 642us/step - loss: 5.6110 - mae: 1.5309\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 644us/step - loss: 5.4570 - mae: 1.5777\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 622us/step - loss: 5.6593 - mae: 1.5624\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 667us/step - loss: 5.4233 - mae: 1.5674\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 664us/step - loss: 5.3256 - mae: 1.5330\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 647us/step - loss: 5.5643 - mae: 1.5185\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 671us/step - loss: 5.2333 - mae: 1.4913\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 670us/step - loss: 4.9575 - mae: 1.4389\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 5.3409 - mae: 1.5539\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 667us/step - loss: 4.8089 - mae: 1.4917\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 664us/step - loss: 5.0545 - mae: 1.5312\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 677us/step - loss: 4.8949 - mae: 1.4998\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 5.2028 - mae: 1.4721\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 676us/step - loss: 4.9353 - mae: 1.4879\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 671us/step - loss: 5.0371 - mae: 1.5023\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 668us/step - loss: 5.0026 - mae: 1.5123\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 649us/step - loss: 4.6372 - mae: 1.4431\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 669us/step - loss: 4.9763 - mae: 1.4764\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 679us/step - loss: 4.7525 - mae: 1.4029\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 657us/step - loss: 4.9531 - mae: 1.4700\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 663us/step - loss: 4.8003 - mae: 1.4633\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 650us/step - loss: 4.7897 - mae: 1.4479\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 653us/step - loss: 4.4961 - mae: 1.4672\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 669us/step - loss: 4.3430 - mae: 1.3484\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 670us/step - loss: 4.6944 - mae: 1.4270\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 673us/step - loss: 4.3657 - mae: 1.4085\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 663us/step - loss: 4.7124 - mae: 1.4440\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 676us/step - loss: 4.7027 - mae: 1.3574\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 672us/step - loss: 4.4567 - mae: 1.3866\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 666us/step - loss: 4.3831 - mae: 1.3531\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 658us/step - loss: 4.5633 - mae: 1.4717\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 659us/step - loss: 4.3576 - mae: 1.4317\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 670us/step - loss: 4.0931 - mae: 1.3667\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 661us/step - loss: 4.0986 - mae: 1.4131\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 667us/step - loss: 4.4768 - mae: 1.4016\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 667us/step - loss: 3.6499 - mae: 1.3316\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 648us/step - loss: 4.1273 - mae: 1.3656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3c8a9bd48>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_targets, epochs=100, batch_size=1, verbose=1)\n",
    "    # batch_size를 지정해서 mini_batch를 할건지 안할건지\n",
    "    # 1은 안하겠다는 의미 \n",
    "    # verbose : 결과를 볼지 말지 정하는 옵션(1 : 본다, 0 : 안본다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 215us/step\n",
      "15.38832197002336 2.559119939804077\n"
     ]
    }
   ],
   "source": [
    "mse, mae = model.evaluate(test_data, test_targets, verbose=1)\n",
    "print(mse, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    mse : 평균 제곱 오차\n",
    "    mae : 평균 절대값 오차  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습3. 인공신경망 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10.3012\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 7.7528\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.8415\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.4079\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.3325\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 2.5257\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 1.9204\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 1.4661\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 1.1252\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.8692\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.6769\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.5324\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.4238\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.3420\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.2804\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.2340\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.1988\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.1722\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.1520\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.1365\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.1246\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.1155\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.1084\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 213us/step - loss: 0.1028\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0983\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 186us/step - loss: 0.0947\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0918\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0893\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0872\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0854\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0838\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0824\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0811\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0799\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0787\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0777\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0766\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0757\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 184us/step - loss: 0.0747\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0738\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0729\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0720\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0711\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0702\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0694\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0685\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0677\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0669\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0661\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 398us/step - loss: 0.0653\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0645\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0638\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 198us/step - loss: 0.0630\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0623\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0615\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0608\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0601\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0594\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0586\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0579\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0573\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0566\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0559\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0552\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0546\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 236us/step - loss: 0.0539\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 163us/step - loss: 0.0533\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0527\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0520\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0514\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0508\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0502\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0496\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0490\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0484\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0478\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0473\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0467\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 212us/step - loss: 0.0462\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0456\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0451\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0445\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0440\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0435\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0430\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0424\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0419\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0414\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0409\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0405\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 186us/step - loss: 0.0400\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0395\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0390\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0386\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0381\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0377\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0372\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0368\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0363\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0359\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0355\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0346\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0342\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 209us/step - loss: 0.0338\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 190us/step - loss: 0.0334\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0330\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0326\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0322\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0318\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 0.0315\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 398us/step - loss: 0.0311\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 187us/step - loss: 0.0307\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0304\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0300\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0296\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0293\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 187us/step - loss: 0.0289\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0286\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 193us/step - loss: 0.0283\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0279\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0276\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 176us/step - loss: 0.0273\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0269\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0266\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0263\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 210us/step - loss: 0.0260\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 189us/step - loss: 0.0257\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0254\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0251\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 206us/step - loss: 0.0248\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 201us/step - loss: 0.0245\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 192us/step - loss: 0.0242\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0239\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0236\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0233\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0230\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0228\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0225\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0222\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0220\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0217\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0215\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0212\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 198us/step - loss: 0.0209\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 191us/step - loss: 0.0207\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0204\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0202\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0200\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0197\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0195\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0193\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0190\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0188\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 213us/step - loss: 0.0186\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 186us/step - loss: 0.0184\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0181\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 201us/step - loss: 0.0179\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0177\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0175\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0173\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0171\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0169\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0167\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0165\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0163\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0161\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0159\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0157\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0155\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0153\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0152\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0150\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0148\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0146\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0144\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0143\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0141\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0139\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0138\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0136\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0134\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0133\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0131\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0130\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0128\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 0.0127\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0125\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0124\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0122\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0121\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0119\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0118\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0116\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0115\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 0.0114\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 197us/step - loss: 0.0112\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0111\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0110\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0108\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0107\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0106\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 203us/step - loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 196us/step - loss: 0.0103\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0102\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0101\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0100\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 0.0099\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0097\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0096\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0095\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0094\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0093\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0092\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0091\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0090\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0088\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0087\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0086\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0085\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0084\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 201us/step - loss: 0.0083\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0082\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0081\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0080\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0079\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0078\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0078\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0077\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0076\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0075\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0074\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0073\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0072\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0071\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0070\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0070\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0069\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0068\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0067\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0066\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0066\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0065\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0064\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0063\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0062\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0062\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0061\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0060\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0060\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0059\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0058\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0057\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0057\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0056\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0055\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0055\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0054\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0053\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0053\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0052\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0052\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0051\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0050\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0050\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0049\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0049\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0048\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0047\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0047\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0046\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0046\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0045\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0045\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0044\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0044\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0043\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0043\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0042\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0042\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0041\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0041\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0040\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0040\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0039\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0039\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0038\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0038\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0037\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0037\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0036\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0036\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0036\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0035\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0035\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0034\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 201us/step - loss: 0.0034\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0034\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0033\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0033\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0032\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0032\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0032\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0031\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0030\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0030\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0030\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0029\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0029\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0029\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0028\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0028\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 196us/step - loss: 0.0028\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0027\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0027\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0027\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0026\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0026\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0026\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0025\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0025\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0025\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0025\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0024\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0024\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0024\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0023\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0023\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0023\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0023\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0022\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0022\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0022\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0022\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0021\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0021\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 203us/step - loss: 0.0021\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0021\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0020\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0020\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0020\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0020\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0019\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0019\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0019\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0019\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0018\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0018\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0018\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0018\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0018\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0017\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0017\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 198us/step - loss: 0.0017\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 399us/step - loss: 0.0017\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0017\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0016\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0016\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0016\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 0.0016\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 197us/step - loss: 0.0016\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0015\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 201us/step - loss: 0.0015\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 198us/step - loss: 0.0015\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0015\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 0.0015\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 196us/step - loss: 0.0015\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0014\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0014\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0014\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0014\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0014\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 0.0013\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 197us/step - loss: 0.0013\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0013\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0013\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0013\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0013\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0013\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0012\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0012\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0012\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0012\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0012\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0012\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0012\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0011\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0011\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0011\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0011\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0011\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 0.0011\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0011\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 0.0010\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 0.0010\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 9.8871e-04\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 9.7694e-04\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 9.6532e-04\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 9.5383e-04\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 9.4248e-04\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 9.3126e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 202us/step - loss: 9.2017e-04\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 197us/step - loss: 9.0922e-04\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 8.9840e-04\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 8.8770e-04\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 8.7714e-04\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 8.6670e-04\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 8.5639e-04\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 8.4619e-04\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 8.3612e-04\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 8.2616e-04\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 8.1633e-04\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 203us/step - loss: 8.0662e-04\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 7.9702e-04\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 203us/step - loss: 7.8753e-04\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 7.7816e-04\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 7.6890e-04\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 7.5975e-04\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 7.5071e-04\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 7.4177e-04\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 7.3294e-04\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 7.2421e-04\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 7.1560e-04\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 7.0708e-04\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 6.9866e-04\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 6.9035e-04\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 6.8213e-04\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 6.7401e-04\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 6.6599e-04\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 6.5807e-04\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 6.5023e-04\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 6.4249e-04\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 6.3485e-04\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 6.2729e-04\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 6.1983e-04\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 6.1245e-04\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 6.0516e-04\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 5.9796e-04\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.9084e-04\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.8381e-04\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.7686e-04\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.7000e-04\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.6321e-04\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.5650e-04\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.4988e-04\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 5.4334e-04\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 201us/step - loss: 5.3687e-04\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.3048e-04\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 5.2416e-04\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 5.1793e-04\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 5.1177e-04\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 5.0567e-04\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 203us/step - loss: 4.9966e-04\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 196us/step - loss: 4.9371e-04\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 4.8783e-04\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 4.8203e-04\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.7630e-04\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.7062e-04\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 4.6502e-04\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 4.5949e-04\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.5402e-04\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.4862e-04\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 4.4328e-04\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 4.3800e-04\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 4.3279e-04\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 4.2764e-04\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 4.2254e-04\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 4.1752e-04\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.1255e-04\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.0764e-04\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 4.0278e-04\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.9799e-04\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.9326e-04\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.8857e-04\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.8395e-04\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.7938e-04\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.7487e-04\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.7040e-04\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.6599e-04\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.6164e-04\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 3.5734e-04\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.5308e-04\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.4888e-04\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 3.4473e-04\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.4062e-04\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.3657e-04\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.3257e-04\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.2861e-04\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.2470e-04\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 199us/step - loss: 3.2083e-04\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 3.1701e-04\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 200us/step - loss: 3.1324e-04\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 3.0951e-04\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 3.0583e-04\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 3.0219e-04\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 0us/step - loss: 2.9859e-04\n",
      "Targets :  [5 7 9]\n",
      "Prediction :  [[4.9911456]\n",
      " [7.0015535]\n",
      " [9.011961 ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([0, 1, 2, 3, 4])\n",
    "y = X * 2 + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(1, )))\n",
    "model.compile(loss=\"mse\", optimizer=\"SGD\")\n",
    "model.fit(X, y, epochs=500, verbose=1)\n",
    "\n",
    "print(\"Targets : \", y[2:])\n",
    "print(\"Prediction : \", model.predict(X[2:]))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습4. 손글씨 데이터 \n",
    "\n",
    "    from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot 인코딩\n",
    "\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)  \n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력데이터 2차원으로 변경\n",
    "X_train = X_train.reshape(60000, 28*28)/255.astype(\"float32\")\n",
    "X_test = X_test.reshape(10000, 28*28)/255.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [5 0 4 1 9 2 1 3 1 4]\n",
    "    이렇게 나온 결과를 one-hot으로 바꾸었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적합도 검증을 위한 vlidation 분할(k-fold)\n",
    "\n",
    "x_val = X_train[:12600]  # 일단 절반정도만 테스트\n",
    "X_train = X_train[12600:]\n",
    "y_val = y_train[:12600]\n",
    "y_train = y_train[12600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# 레이어 1\n",
    "# model.add(Dense(units=64, input_shape=(28*28, ), activation = \"relu\"))\n",
    "model.add(Dense(64, input_dim=28*28, activation = \"relu\"))\n",
    "\n",
    "#레이어 2\n",
    "model.add(Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    model.add(Dense(units=64, input_dim=28*28, activation = \"relu\"))\n",
    "        input_dim :  input_shape이랑 똑같은 기능인데 적는 문법만 다르다.\n",
    "        \n",
    "        \n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "        이진 분류가 아니므로 다중분류방식인 softmax를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 계산\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47400 samples, validate on 12600 samples\n",
      "Epoch 1/5\n",
      "47400/47400 [==============================] - 41s 859us/step - loss: 32.9024 - accuracy: 0.1057 - val_loss: 2.3026 - val_accuracy: 0.1128\n",
      "Epoch 2/5\n",
      "47400/47400 [==============================] - 40s 845us/step - loss: 2.3039 - accuracy: 0.1079 - val_loss: 2.3035 - val_accuracy: 0.1032\n",
      "Epoch 3/5\n",
      "47400/47400 [==============================] - 40s 848us/step - loss: 2.3038 - accuracy: 0.1053 - val_loss: 2.3031 - val_accuracy: 0.1128\n",
      "Epoch 4/5\n",
      "47400/47400 [==============================] - 39s 819us/step - loss: 2.3039 - accuracy: 0.1065 - val_loss: 2.3032 - val_accuracy: 0.1128\n",
      "Epoch 5/5\n",
      "47400/47400 [==============================] - 39s 826us/step - loss: 2.3035 - accuracy: 0.1073 - val_loss: 2.3031 - val_accuracy: 0.1128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3d12618c8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=1, validation_data=(x_val, y_val))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    validation_data :K-fold 를 사용할 수 있다. \n",
    "                    훈련용 데이터를 통해 적합도를 검사 -> validation_data=(,)\n",
    "                    \n",
    "                    \n",
    "    정확도가 형편이 없다 10%쯤 이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 34us/step\n",
      "[2.3026211181640623, 0.11349999904632568]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6025, 1635, 2125, 6616, 7703, 5051, 4272, 1843, 9883, 9487])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 해보자!\n",
    "# 10개를 랜덤으로 뽑아오기\n",
    "\n",
    "xhat_idx = np.random.choice(X_test.shape[0], 10)\n",
    "xhat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat = X_test[xhat_idx]\n",
    "xhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict_classes(xhat)\n",
    "yhat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    예측을 다.. 음 왜이래 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True :  4 predict :  1\n",
      "True :  5 predict :  1\n",
      "True :  5 predict :  1\n",
      "True :  2 predict :  1\n",
      "True :  0 predict :  1\n",
      "True :  0 predict :  1\n",
      "True :  9 predict :  1\n",
      "True :  0 predict :  1\n",
      "True :  5 predict :  1\n",
      "True :  2 predict :  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10) :\n",
    "    print(\"True : \", np.argmax(y_test[xhat_idx[i]]), \"predict : \", yhat[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 그리기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47400 samples, validate on 12600 samples\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/5\n",
      "47400/47400 [==============================] - 41s 859us/step - loss: 0.2509 - accuracy: 0.9241 - val_loss: 0.1952 - val_accuracy: 0.9406\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/5\n",
      "47400/47400 [==============================] - 40s 836us/step - loss: 0.1274 - accuracy: 0.9607 - val_loss: 0.1144 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "47400/47400 [==============================] - 41s 857us/step - loss: 0.0962 - accuracy: 0.9696 - val_loss: 0.1251 - val_accuracy: 0.9627\n",
      "Epoch 4/5\n",
      "47400/47400 [==============================] - 41s 858us/step - loss: 0.0758 - accuracy: 0.9758 - val_loss: 0.1091 - val_accuracy: 0.9683\n",
      "Epoch 5/5\n",
      "47400/47400 [==============================] - 40s 842us/step - loss: 0.0631 - accuracy: 0.9796 - val_loss: 0.1163 - val_accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "# 위에서 했던 keras를 tensorflow 그래프로 그린다. \n",
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# one hot 인코딩\n",
    "y_train = np_utils.to_categorical(y_train)  \n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 입력데이터 2차원으로 변경\n",
    "X_train = X_train.reshape(60000, 28*28).astype(\"float32\")/255\n",
    "X_test = X_test.reshape(10000, 28*28).astype(\"float32\")/255\n",
    "\n",
    "\n",
    "# 적합도 검증을 위한 vlidation 분할(k-fold)\n",
    "x_val = X_train[:12600]  # 일단 절반정도만 테스트\n",
    "X_train = X_train[12600:]\n",
    "y_val = y_train[:12600]\n",
    "y_train = y_train[12600:]\n",
    "\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "# 레이어 1\n",
    "model.add(Dense(64, input_dim=28*28, activation = \"relu\"))\n",
    "#레이어 2\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "# 비용 계산\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "###################\n",
    "# 텐서보드 설정\n",
    "tf_hist = keras.callbacks.TensorBoard(log_dir=\"./graph\", write_graph=True, write_images=True)\n",
    "###################\n",
    "\n",
    "# 훈련\n",
    "hist = model.fit(X_train, y_train, epochs=5, batch_size=1, validation_data=(x_val, y_val), \n",
    "                callbacks= [tf_hist])\n",
    "    # 훈련할때마다 호출하게 옵션으로 던져준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 실행\n",
    "\n",
    "    cmd (tf1) 생성된 폴더 바로 상위폴더 위치로 가서\n",
    "    \n",
    "    tensorboard --logdir = graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "\n",
    "# 나중에 다시 불러와서 사용하기 위함\n",
    "model.save(\"data/mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러와서 다시 사용하기\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model(\"data/mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True :  4 predict :  4\n",
      "True :  7 predict :  7\n",
      "True :  7 predict :  7\n",
      "True :  0 predict :  0\n",
      "True :  8 predict :  8\n",
      "True :  2 predict :  2\n",
      "True :  7 predict :  7\n",
      "True :  1 predict :  1\n",
      "True :  3 predict :  3\n",
      "True :  7 predict :  7\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_test = X_test.reshape(10000, 784).astype(\"float32\") / 255.0\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "xhat_idx = np.random.choice(X_test.shape[0], 10)\n",
    "xhat = X_test[xhat_idx]\n",
    "\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "\n",
    "for i in range(10) :\n",
    "    print(\"True : \", np.argmax(y_test[xhat_idx[i]]), \"predict : \", yhat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 21us/step\n",
      "[0.09933118558095302, 0.9715999960899353]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조기 종료 : EarlyStopping(monitor=, min_data=, patience=)\n",
    "    돌다가 성능 향상이 없다면, epoch이 남았더라도 강제로 그냥 종료시켜버린다.\n",
    "\n",
    "    monitor : 관찰하고자 하는 항목, 주로 val_accuracy  를 살펴보게 됨\n",
    "    \n",
    "    min_data : 개선되고 있다고 판단하기 위한 최소 변화량, 보통 0을 지정\n",
    "    \n",
    "    patience : 지정된 값까지는 기다렸다가 종료 \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47400 samples, validate on 12600 samples\n",
      "Epoch 1/50\n",
      "47400/47400 [==============================] - 2s 44us/step - loss: 0.7806 - accuracy: 0.8017 - val_loss: 0.4213 - val_accuracy: 0.8915\n",
      "Epoch 2/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.3778 - accuracy: 0.8960 - val_loss: 0.3357 - val_accuracy: 0.9095\n",
      "Epoch 3/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.3214 - accuracy: 0.9099 - val_loss: 0.2994 - val_accuracy: 0.9162\n",
      "Epoch 4/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.2900 - accuracy: 0.9189 - val_loss: 0.2751 - val_accuracy: 0.9225\n",
      "Epoch 5/50\n",
      "47400/47400 [==============================] - 2s 40us/step - loss: 0.2669 - accuracy: 0.9248 - val_loss: 0.2550 - val_accuracy: 0.9269\n",
      "Epoch 6/50\n",
      "47400/47400 [==============================] - 2s 40us/step - loss: 0.2476 - accuracy: 0.9305 - val_loss: 0.2384 - val_accuracy: 0.9302\n",
      "Epoch 7/50\n",
      "47400/47400 [==============================] - 2s 40us/step - loss: 0.2318 - accuracy: 0.9347 - val_loss: 0.2247 - val_accuracy: 0.9344\n",
      "Epoch 8/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.2182 - accuracy: 0.9389 - val_loss: 0.2132 - val_accuracy: 0.9377\n",
      "Epoch 9/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.2058 - accuracy: 0.9425 - val_loss: 0.2036 - val_accuracy: 0.9400\n",
      "Epoch 10/50\n",
      "47400/47400 [==============================] - 2s 41us/step - loss: 0.1952 - accuracy: 0.9455 - val_loss: 0.1974 - val_accuracy: 0.9424\n",
      "Epoch 11/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.1860 - accuracy: 0.9479 - val_loss: 0.1866 - val_accuracy: 0.9451\n",
      "Epoch 12/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.1772 - accuracy: 0.9511 - val_loss: 0.1830 - val_accuracy: 0.9466\n",
      "Epoch 13/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.1695 - accuracy: 0.9527 - val_loss: 0.1754 - val_accuracy: 0.9492\n",
      "Epoch 14/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.1626 - accuracy: 0.9546 - val_loss: 0.1685 - val_accuracy: 0.9499\n",
      "Epoch 15/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.1562 - accuracy: 0.9555 - val_loss: 0.1638 - val_accuracy: 0.9524\n",
      "Epoch 16/50\n",
      "47400/47400 [==============================] - 2s 40us/step - loss: 0.1501 - accuracy: 0.9574 - val_loss: 0.1601 - val_accuracy: 0.9532\n",
      "Epoch 17/50\n",
      "47400/47400 [==============================] - 2s 40us/step - loss: 0.1448 - accuracy: 0.9595 - val_loss: 0.1547 - val_accuracy: 0.9557\n",
      "Epoch 18/50\n",
      "47400/47400 [==============================] - 2s 40us/step - loss: 0.1398 - accuracy: 0.9608 - val_loss: 0.1510 - val_accuracy: 0.9557\n",
      "Epoch 19/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.1350 - accuracy: 0.9619 - val_loss: 0.1498 - val_accuracy: 0.9566\n",
      "Epoch 20/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.1308 - accuracy: 0.9632 - val_loss: 0.1443 - val_accuracy: 0.9579\n",
      "Epoch 21/50\n",
      "47400/47400 [==============================] - 2s 42us/step - loss: 0.1266 - accuracy: 0.9647 - val_loss: 0.1415 - val_accuracy: 0.9587\n",
      "Epoch 22/50\n",
      "47400/47400 [==============================] - 2s 41us/step - loss: 0.1229 - accuracy: 0.9657 - val_loss: 0.1372 - val_accuracy: 0.9596\n",
      "Epoch 23/50\n",
      "47400/47400 [==============================] - 2s 41us/step - loss: 0.1192 - accuracy: 0.9668 - val_loss: 0.1359 - val_accuracy: 0.9600\n",
      "Epoch 24/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.1158 - accuracy: 0.9679 - val_loss: 0.1327 - val_accuracy: 0.9606\n",
      "Epoch 25/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.1127 - accuracy: 0.9684 - val_loss: 0.1323 - val_accuracy: 0.9607\n",
      "Epoch 26/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.1097 - accuracy: 0.9693 - val_loss: 0.1288 - val_accuracy: 0.9623\n",
      "Epoch 27/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.1067 - accuracy: 0.9702 - val_loss: 0.1281 - val_accuracy: 0.9621\n",
      "Epoch 28/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.1041 - accuracy: 0.9709 - val_loss: 0.1256 - val_accuracy: 0.9629\n",
      "Epoch 29/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.1017 - accuracy: 0.9718 - val_loss: 0.1231 - val_accuracy: 0.9629\n",
      "Epoch 30/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.0991 - accuracy: 0.9724 - val_loss: 0.1221 - val_accuracy: 0.9636\n",
      "Epoch 31/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.0968 - accuracy: 0.9731 - val_loss: 0.1200 - val_accuracy: 0.9639\n",
      "Epoch 32/50\n",
      "47400/47400 [==============================] - 2s 39us/step - loss: 0.0945 - accuracy: 0.9737 - val_loss: 0.1200 - val_accuracy: 0.9644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3cd1afb08>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에 코드 그대로 조기종료 기능 추가\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# one hot 인코딩\n",
    "y_train = np_utils.to_categorical(y_train)  \n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 입력데이터 2차원으로 변경\n",
    "X_train = X_train.reshape(60000, 28*28).astype(\"float32\")/255\n",
    "X_test = X_test.reshape(10000, 28*28).astype(\"float32\")/255\n",
    "\n",
    "\n",
    "# 적합도 검증을 위한 vlidation 분할(k-fold)\n",
    "x_val = X_train[:12600]  # 일단 절반정도만 테스트\n",
    "X_train = X_train[12600:]\n",
    "y_val = y_train[:12600]\n",
    "y_train = y_train[12600:]\n",
    "\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "# 레이어 1\n",
    "model.add(Dense(64, input_dim=28*28, activation = \"relu\"))\n",
    "#레이어 2\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "# 비용 계산\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "# 텐서보드 설정\n",
    "tf_hist = keras.callbacks.TensorBoard(log_dir=\"./graph\", write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "#####################\n",
    "# 조기종료 기능\n",
    "# from keras.callbacks import EarlyStopping\n",
    "early = EarlyStopping()\n",
    "#####################\n",
    "\n",
    "\n",
    "# 훈련\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val), \n",
    "                callbacks= [tf_hist, early])\n",
    "    # 훈련할때마다 호출하게 옵션으로 던져준다.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습5. 붓꽃 데이터 (iris)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.iloc[:, :4].values\n",
    "y = iris.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "y1\n",
    "\n",
    "y2 = pd.get_dummies(y1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련용 테스트용 분리시키기 위해\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.1572 - accuracy: 0.3917 - val_loss: 1.0100 - val_accuracy: 0.5667\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.9499 - accuracy: 0.6583 - val_loss: 0.9760 - val_accuracy: 0.5667\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.8479 - accuracy: 0.6833 - val_loss: 0.8646 - val_accuracy: 0.5667\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.7429 - accuracy: 0.6917 - val_loss: 0.7412 - val_accuracy: 0.5667\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.6716 - accuracy: 0.7083 - val_loss: 0.6691 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6278 - accuracy: 0.8000 - val_loss: 0.6238 - val_accuracy: 0.6333\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5780 - accuracy: 0.7667 - val_loss: 0.5887 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.5373 - accuracy: 0.7000 - val_loss: 0.5596 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.5081 - accuracy: 0.7000 - val_loss: 0.5409 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.4815 - accuracy: 0.7000 - val_loss: 0.5122 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.4578 - accuracy: 0.8250 - val_loss: 0.4757 - val_accuracy: 0.7333\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4422 - accuracy: 0.9167 - val_loss: 0.4480 - val_accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4216 - accuracy: 0.9667 - val_loss: 0.4465 - val_accuracy: 0.7333\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4075 - accuracy: 0.8667 - val_loss: 0.4565 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3942 - accuracy: 0.8333 - val_loss: 0.4375 - val_accuracy: 0.7333\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.3807 - accuracy: 0.9083 - val_loss: 0.4027 - val_accuracy: 0.8667\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.3661 - accuracy: 0.9583 - val_loss: 0.3923 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3547 - accuracy: 0.9500 - val_loss: 0.3908 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.3428 - accuracy: 0.9417 - val_loss: 0.3802 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.3312 - accuracy: 0.9667 - val_loss: 0.3567 - val_accuracy: 0.9667\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.3219 - accuracy: 0.9667 - val_loss: 0.3472 - val_accuracy: 0.9667\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3104 - accuracy: 0.9667 - val_loss: 0.3458 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3034 - accuracy: 0.9667 - val_loss: 0.3318 - val_accuracy: 0.9667\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.2875 - accuracy: 0.9667 - val_loss: 0.3361 - val_accuracy: 0.8667\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.2822 - accuracy: 0.9500 - val_loss: 0.3318 - val_accuracy: 0.8667\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2686 - accuracy: 0.9667 - val_loss: 0.2995 - val_accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2611 - accuracy: 0.9667 - val_loss: 0.2817 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.2512 - accuracy: 0.9667 - val_loss: 0.2840 - val_accuracy: 0.9667\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2449 - accuracy: 0.9667 - val_loss: 0.2978 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.2360 - accuracy: 0.9667 - val_loss: 0.2633 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2246 - accuracy: 0.9667 - val_loss: 0.2534 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2173 - accuracy: 0.9667 - val_loss: 0.2561 - val_accuracy: 0.9667\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2105 - accuracy: 0.9667 - val_loss: 0.2385 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.2009 - accuracy: 0.9667 - val_loss: 0.2368 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1947 - accuracy: 0.9667 - val_loss: 0.2424 - val_accuracy: 0.9667\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.1897 - accuracy: 0.9667 - val_loss: 0.2195 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1808 - accuracy: 0.9667 - val_loss: 0.2093 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1761 - accuracy: 0.9667 - val_loss: 0.2041 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.1731 - accuracy: 0.9667 - val_loss: 0.2108 - val_accuracy: 0.9667\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1649 - accuracy: 0.9667 - val_loss: 0.1922 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1591 - accuracy: 0.9667 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1565 - accuracy: 0.9667 - val_loss: 0.1811 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1505 - accuracy: 0.9667 - val_loss: 0.1838 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1475 - accuracy: 0.9667 - val_loss: 0.1858 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1436 - accuracy: 0.9667 - val_loss: 0.1679 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1391 - accuracy: 0.9667 - val_loss: 0.1631 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.1362 - accuracy: 0.9667 - val_loss: 0.1647 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.1332 - accuracy: 0.9667 - val_loss: 0.1638 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1301 - accuracy: 0.9667 - val_loss: 0.1538 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1306 - accuracy: 0.9667 - val_loss: 0.1443 - val_accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1264 - accuracy: 0.9750 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1248 - accuracy: 0.9667 - val_loss: 0.1649 - val_accuracy: 0.9667\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1218 - accuracy: 0.9667 - val_loss: 0.1430 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1166 - accuracy: 0.9667 - val_loss: 0.1334 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.1199 - accuracy: 0.9750 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1152 - accuracy: 0.9750 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 41us/step - loss: 0.1172 - accuracy: 0.9667 - val_loss: 0.1403 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1112 - accuracy: 0.9667 - val_loss: 0.1235 - val_accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1130 - accuracy: 0.9833 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.1096 - accuracy: 0.9667 - val_loss: 0.1444 - val_accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1111 - accuracy: 0.9667 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1068 - accuracy: 0.9667 - val_loss: 0.1155 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1028 - accuracy: 0.9833 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.1015 - accuracy: 0.9667 - val_loss: 0.1206 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1013 - accuracy: 0.9667 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0981 - accuracy: 0.9667 - val_loss: 0.1093 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1011 - accuracy: 0.9833 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.1034 - accuracy: 0.9667 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0968 - accuracy: 0.9667 - val_loss: 0.1065 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0951 - accuracy: 0.9750 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.0942 - accuracy: 0.9750 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.1071 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0921 - accuracy: 0.9667 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0905 - accuracy: 0.9750 - val_loss: 0.0987 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0919 - accuracy: 0.9750 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 51us/step - loss: 0.0902 - accuracy: 0.9667 - val_loss: 0.0940 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0925 - accuracy: 0.9667 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 52us/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0875 - accuracy: 0.9667 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0876 - accuracy: 0.9750 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0869 - accuracy: 0.9750 - val_loss: 0.0896 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0857 - accuracy: 0.9750 - val_loss: 0.0899 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0901 - accuracy: 0.9667 - val_loss: 0.0940 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0843 - accuracy: 0.9667 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0865 - accuracy: 0.9667 - val_loss: 0.0910 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0841 - accuracy: 0.9667 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0827 - accuracy: 0.9750 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0844 - accuracy: 0.9750 - val_loss: 0.0839 - val_accuracy: 0.9667\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0849 - accuracy: 0.9667 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.0836 - accuracy: 0.9667 - val_loss: 0.0882 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0805 - accuracy: 0.9750 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0831 - accuracy: 0.9667 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.0802 - accuracy: 0.9750 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0792 - accuracy: 0.9750 - val_loss: 0.0783 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0786 - accuracy: 0.9750 - val_loss: 0.0800 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0828 - accuracy: 0.9667 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0783 - accuracy: 0.9667 - val_loss: 0.0755 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 및 훈련\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "#layer1\n",
    "model.add(Dense(64, input_shape=(4, ), activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "hist = model.fit(X_train, y_train, epochs=100, validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a3ca081508>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "print(hist.history.keys())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])\n",
    "\n",
    "plt.legend([\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 33us/step\n",
      "0.07546418160200119 1.0\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "<function confusion_matrix at 0x000001A3BAF6BA68>\n",
      "품종예측 :  ['setosa']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 예측 테스트 \n",
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(confusion_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# 가상으로 입력\n",
    "test_set = np.array([[5, 2.9, 1, 0.2]])\n",
    "print(\"품종예측 : \", iris[\"species\"].unique()[model.predict_classes(test_set)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    100% 다 맞춘것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN  (모듈화)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_num, output_num, hidden_layer) :\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hidden_layer[0], input_shape=(input_num, ), activation=\"relu\", name=\"hidden-1\"))\n",
    "    model.add(Dense(hidden_layer[1], activation=\"relu\", name=\"hidden-2\"))\n",
    "    model.add(Dense(hidden_layer[2], activation=\"relu\", name=\"hidden-3\"))\n",
    "    model.add(Dense(hidden_layer[3], activation=\"relu\", name=\"hidden-4\"))\n",
    "    \n",
    "    # 버리기\n",
    "    model.add(keras.layers.core.Dropout(0.2)) # 20%만 버리고 나머지 실행 \n",
    "    \n",
    "    model.add(Dense(output_num, activation=\"softmax\"))\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2529 - accuracy: 0.9243\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0967 - accuracy: 0.9711\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0666 - accuracy: 0.9790\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.98 - 3s 50us/step - loss: 0.0481 - accuracy: 0.9849\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0393 - accuracy: 0.9874\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#one_hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "X_train = X_train.reshape(60000, 28*28).astype(\"float32\") / 255\n",
    "X_test = X_test.reshape(10000, 28*28).astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "#파라미터 \n",
    "input_num = 784\n",
    "output_num = 10\n",
    "hidden_layer = [255,255,255,255]\n",
    "\n",
    "model = make_model(input_num, output_num, hidden_layer)  # 입력갯수, 출력갯수, [레이어갯수] 를 인자로 한다.\n",
    "hist = model.fit(X_train, y_train, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    튜닝을 통해 성능을 더 올려야 한다. 97%면 되도 좀 좋은거 같은데 \n",
    "    \n",
    "    100, 30, 5  ->  255,255,255 로 수정하고 98%까지 올라갔다. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer를 사용해서 한다\n",
    "\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# conv layer : 필터갯수는 32개, 필터 크기는 3*3\n",
    "# 입력 데이터 : 28*28*1 (흑백이라 1)\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))  # 여기는 input_shape가 들어가면 안되죠\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "#마지막은 max pooling을 해도되고 안해도 된다.\n",
    "\n",
    "\n",
    "#FC 로 넘기기위한 중간과정\n",
    "model.add(layers.Flatten())  #1차원으로 펼치기 위함\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: nan - accuracy: 0.1064\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: nan - accuracy: 0.0987\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: nan - accuracy: 0.0987\n"
     ]
    }
   ],
   "source": [
    "# 방금전 코드를 가져왔다.\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#one_hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1).astype(\"float32\") / 255\n",
    "X_test = X_test.reshape(10000, 28, 28, 1).astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "# #파라미터 \n",
    "# input_num = 784\n",
    "# output_num = 10\n",
    "# hidden_layer = [255,255,255,255]\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "hist = model.fit(X_train, y_train, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
