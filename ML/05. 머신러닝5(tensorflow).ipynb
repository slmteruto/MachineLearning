{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acorn\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\acorn\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "import mglearn\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()    \n",
    "# 한글폰트가 기본적으로 없다.  그래서 따로 등록해서 사용하면 됨\n",
    "font_name\n",
    "#(c\\windows\\fonts  가 기본폰트)\n",
    "\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "# - 마이너스 표시도 깨진다.\n",
    "mpl.rcParams[\"axes.unicode_minus\"]=False    #마이너스를 문자로 쓰지 않고 숫자로 쓰겠다. 라는 뜻\n",
    "\n",
    "\n",
    "import mglearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "    확률의 곱의 법칙\n",
    "    \n",
    "    어떤 확률이 발생하기 위해 그 확률이 발생할때 다른 사건 발생확률이 어찌 되는가?\n",
    "    \n",
    "    스팸메일 구별할 때 많이 사용함. \n",
    "    \n",
    "    - 선형모델과 유사(Logistic Regression, LinearSVC...)\n",
    "    - 훈련속도 빠르지만 일반화 성능이 조금 뒤쳐진다. \n",
    "    - 확률로 뭔가를 계산할 때 사용하는 알고리즘\n",
    "    \n",
    "    - 데이터에 따라 알고리즘이 나뉨\n",
    "    \n",
    "        1) 연속적인 데이터일 때 : 가우시안(Gaussian) Naive Bayes\n",
    "        2) 이산적인 데이터일 때 : 베르누이(Bernoulli) Naive Bayes 또는 MultinomialNB\n",
    "    - Alpha 파라미터를 통해 복잡도 조절\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고자료 : 나이브베이즈.pdf\n",
    "\n",
    "    1페이지\n",
    "    \n",
    "        과일 세개 중 바나나 뽑을 확률\n",
    "        과일 세개 중 사과를 뽑을 확률\n",
    "        \n",
    "        p : 어떤 사건이 일어날 확률\n",
    "        \n",
    "        확률의 합 : 별개의 확률\n",
    "        \n",
    "        확률의 곱 : 연속적 일어나거나, 동시에 일어나는 경우        \n",
    "            조건부 확률 : 어떤 사건이 발생할 때 그 안에서 다른 사건이 발생할 확률\n",
    "                1) 비올때 우산이 팔릴 확률  : P(A) * P(B|A)\n",
    "                                                    P(B|A) = P(A B) / P(B)............\n",
    "            \n",
    "            \n",
    "    3페이지\n",
    "        free라는 단어가 들어갔을 때 스팸메일일 가능성이 있다.\n",
    "        \n",
    "        그럴 때 공식들 \n",
    "        \n",
    "    4페이지\n",
    "        10통의 메일중  3통은 스팸메일이다.\n",
    "        free라는 단어는 4통이다.\n",
    "        \n",
    "        free라는 단어가 들어갔어도 스팸은 아니긴 하다.\n",
    "        \n",
    "        확률이 어느정도인지  계산해보면\n",
    "        50%가 나온다.\n",
    "        \n",
    "    \n",
    "        그냥 확률로 계산하면 되는데 이게 머신러닝으로 돌릴만한 일인가?\n",
    "        \n",
    "        맞다.\n",
    "        \n",
    "        \n",
    "        왜냐하면 여기서는 free라는 단어로만 예시를 들었지 실질적으론 여러단어로 계산해야되기 때문이다.\n",
    "        \n",
    "        \n",
    "        \n",
    "    6페이지\n",
    "        \n",
    "        그 와중에 coupon이라는 단어가 들어가면 더 스팸이 연관성에 대해 복잡해지므로\n",
    "        \n",
    "        계산 식이 복잡해진다. \n",
    "        \n",
    "    7페이지 이후\n",
    "        코딩 하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 1 : iris (연속적인 데이터)\n",
    "\n",
    "\n",
    "연속적이기 때문에 가우시안 NB를 써서 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = sklearn.datasets.load_iris()\n",
    "\n",
    "# DF화\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df[\"target\"] = iris.target\n",
    "df.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
